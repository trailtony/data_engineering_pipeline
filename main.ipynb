{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd06d25",
   "metadata": {},
   "source": [
    "# Step by Step: Wrangling and Tidying Data from SQLite Tables\n",
    "\n",
    "This notebook demonstrates a systematic approach to wrangle and tidy data from SQLite tables using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0667a35",
   "metadata": {},
   "source": [
    "## 1. Load Data from SQLite Tables\n",
    "\n",
    "Use `pandas.read_sql_query` to load the tables (`students`, `courses`, `student_jobs`) from the SQLite database into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e75cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "con = sqlite3.connect(\"cademycode.db\")\n",
    "\n",
    "# Load tables into DataFrames\n",
    "students = pd.read_sql_query(\"SELECT * FROM cademycode_students\", con)\n",
    "courses = pd.read_sql_query(\"SELECT * FROM cademycode_courses\", con)\n",
    "student_jobs = pd.read_sql_query(\"SELECT * FROM cademycode_student_jobs\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77aa54",
   "metadata": {},
   "source": [
    "## 2. Inspect DataFrames\n",
    "\n",
    "Use `.head()`, `.info()`, and `.describe()` to get an overview of the data and identify potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb730d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uuid             name         dob sex  \\\n",
      "0     1  Annabelle Avery  1943-07-03   F   \n",
      "1     2      Micah Rubio  1991-02-07   M   \n",
      "2     3       Hosea Dale  1989-12-07   M   \n",
      "3     4     Mariann Kirk  1988-07-31   F   \n",
      "4     5  Lucio Alexander  1963-08-31   M   \n",
      "\n",
      "                                        contact_info job_id num_course_taken  \\\n",
      "0  {\"mailing_address\": \"303 N Timber Key, Irondal...    7.0              6.0   \n",
      "1  {\"mailing_address\": \"767 Crescent Fair, Shoals...    7.0              5.0   \n",
      "2  {\"mailing_address\": \"P.O. Box 41269, St. Bonav...    7.0              8.0   \n",
      "3  {\"mailing_address\": \"517 SE Wintergreen Isle, ...    6.0              7.0   \n",
      "4  {\"mailing_address\": \"18 Cinder Cliff, Doyles b...    7.0             14.0   \n",
      "\n",
      "  current_career_path_id time_spent_hrs  \n",
      "0                    1.0           4.99  \n",
      "1                    8.0            4.4  \n",
      "2                    8.0           6.74  \n",
      "3                    9.0          12.31  \n",
      "4                    3.0           5.64  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   uuid                    5000 non-null   int64 \n",
      " 1   name                    5000 non-null   object\n",
      " 2   dob                     5000 non-null   object\n",
      " 3   sex                     5000 non-null   object\n",
      " 4   contact_info            5000 non-null   object\n",
      " 5   job_id                  4995 non-null   object\n",
      " 6   num_course_taken        4749 non-null   object\n",
      " 7   current_career_path_id  4529 non-null   object\n",
      " 8   time_spent_hrs          4529 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 351.7+ KB\n",
      "None\n",
      "               uuid           name         dob   sex  \\\n",
      "count   5000.000000           5000        5000  5000   \n",
      "unique          NaN           4998        4492     3   \n",
      "top             NaN  Robbie Davies  1993-08-03     M   \n",
      "freq            NaN              2           4  1995   \n",
      "mean    2500.500000            NaN         NaN   NaN   \n",
      "std     1443.520003            NaN         NaN   NaN   \n",
      "min        1.000000            NaN         NaN   NaN   \n",
      "25%     1250.750000            NaN         NaN   NaN   \n",
      "50%     2500.500000            NaN         NaN   NaN   \n",
      "75%     3750.250000            NaN         NaN   NaN   \n",
      "max     5000.000000            NaN         NaN   NaN   \n",
      "\n",
      "                                             contact_info job_id  \\\n",
      "count                                                5000   4995   \n",
      "unique                                               5000      8   \n",
      "top     {\"mailing_address\": \"303 N Timber Key, Irondal...    2.0   \n",
      "freq                                                    1    706   \n",
      "mean                                                  NaN    NaN   \n",
      "std                                                   NaN    NaN   \n",
      "min                                                   NaN    NaN   \n",
      "25%                                                   NaN    NaN   \n",
      "50%                                                   NaN    NaN   \n",
      "75%                                                   NaN    NaN   \n",
      "max                                                   NaN    NaN   \n",
      "\n",
      "       num_course_taken current_career_path_id time_spent_hrs  \n",
      "count              4749                   4529           4529  \n",
      "unique               16                     10           2192  \n",
      "top                 5.0                    5.0          17.47  \n",
      "freq                341                    476              8  \n",
      "mean                NaN                    NaN            NaN  \n",
      "std                 NaN                    NaN            NaN  \n",
      "min                 NaN                    NaN            NaN  \n",
      "25%                 NaN                    NaN            NaN  \n",
      "50%                 NaN                    NaN            NaN  \n",
      "75%                 NaN                    NaN            NaN  \n",
      "max                 NaN                    NaN            NaN  \n",
      "   career_path_id      career_path_name  hours_to_complete\n",
      "0               1        data scientist                 20\n",
      "1               2         data engineer                 20\n",
      "2               3          data analyst                 12\n",
      "3               4  software engineering                 25\n",
      "4               5      backend engineer                 18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   career_path_id     10 non-null     int64 \n",
      " 1   career_path_name   10 non-null     object\n",
      " 2   hours_to_complete  10 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 372.0+ bytes\n",
      "None\n",
      "        career_path_id career_path_name  hours_to_complete\n",
      "count         10.00000               10          10.000000\n",
      "unique             NaN               10                NaN\n",
      "top                NaN   data scientist                NaN\n",
      "freq               NaN                1                NaN\n",
      "mean           5.50000              NaN          21.900000\n",
      "std            3.02765              NaN           6.707376\n",
      "min            1.00000              NaN          12.000000\n",
      "25%            3.25000              NaN          18.500000\n",
      "50%            5.50000              NaN          20.000000\n",
      "75%            7.75000              NaN          26.500000\n",
      "max           10.00000              NaN          35.000000\n",
      "   job_id        job_category  avg_salary\n",
      "0       1           analytics       86000\n",
      "1       2            engineer      101000\n",
      "2       3  software developer      110000\n",
      "3       4            creative       66000\n",
      "4       5  financial services      135000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   job_id        13 non-null     int64 \n",
      " 1   job_category  13 non-null     object\n",
      " 2   avg_salary    13 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 444.0+ bytes\n",
      "None\n",
      "           job_id job_category     avg_salary\n",
      "count   13.000000           13      13.000000\n",
      "unique        NaN           10            NaN\n",
      "top           NaN     creative            NaN\n",
      "freq          NaN            2            NaN\n",
      "mean     4.384615          NaN   89230.769231\n",
      "std      2.662657          NaN   34727.879881\n",
      "min      0.000000          NaN   10000.000000\n",
      "25%      3.000000          NaN   66000.000000\n",
      "50%      4.000000          NaN   86000.000000\n",
      "75%      6.000000          NaN  110000.000000\n",
      "max      9.000000          NaN  135000.000000\n"
     ]
    }
   ],
   "source": [
    "# Inspect students DataFrame\n",
    "print(students.head())\n",
    "print(students.info())\n",
    "print(students.describe(include='all'))\n",
    "\n",
    "# Inspect courses DataFrame\n",
    "print(courses.head())\n",
    "print(courses.info())\n",
    "print(courses.describe(include='all'))\n",
    "\n",
    "# Inspect student_jobs DataFrame\n",
    "print(student_jobs.head())\n",
    "print(student_jobs.info())\n",
    "print(student_jobs.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b2d2c",
   "metadata": {},
   "source": [
    "## 3. Check Data Types\n",
    "\n",
    "Use `.dtypes` to review column data types and ensure they match expected formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bd037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students Data Types:\n",
      "uuid                       int64\n",
      "name                      object\n",
      "dob                       object\n",
      "sex                       object\n",
      "contact_info              object\n",
      "job_id                    object\n",
      "num_course_taken          object\n",
      "current_career_path_id    object\n",
      "time_spent_hrs            object\n",
      "dtype: object\n",
      "\n",
      "Courses Data Types:\n",
      "career_path_id        int64\n",
      "career_path_name     object\n",
      "hours_to_complete     int64\n",
      "dtype: object\n",
      "\n",
      "Student Jobs Data Types:\n",
      "job_id           int64\n",
      "job_category    object\n",
      "avg_salary       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Students Data Types:\")\n",
    "print(students.dtypes)\n",
    "\n",
    "print(\"\\nCourses Data Types:\")\n",
    "print(courses.dtypes)\n",
    "\n",
    "print(\"\\nStudent Jobs Data Types:\")\n",
    "print(student_jobs.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dda9a",
   "metadata": {},
   "source": [
    "## 4. Remove Duplicate Rows\n",
    "\n",
    "Use `.drop_duplicates(inplace=True)` to remove duplicate entries from each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b791d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.drop_duplicates(inplace=True)\n",
    "courses.drop_duplicates(inplace=True)\n",
    "student_jobs.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cd21c",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values\n",
    "\n",
    "Use `.isna().sum()` to identify missing values and decide on strategies (drop, fill, or impute) for handling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90028f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in students:\n",
      "uuid                        0\n",
      "name                        0\n",
      "dob                         0\n",
      "sex                         0\n",
      "contact_info                0\n",
      "job_id                      5\n",
      "num_course_taken          251\n",
      "current_career_path_id    471\n",
      "time_spent_hrs            471\n",
      "dtype: int64\n",
      "\n",
      "Missing values in courses:\n",
      "career_path_id       0\n",
      "career_path_name     0\n",
      "hours_to_complete    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_jobs:\n",
      "job_id          0\n",
      "job_category    0\n",
      "avg_salary      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in students:\")\n",
    "print(students.isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in courses:\")\n",
    "print(courses.isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in student_jobs:\")\n",
    "print(student_jobs.isna().sum())\n",
    "\n",
    "# Example: Drop rows with missing values (customize as needed)\n",
    "students.dropna(inplace=True)\n",
    "courses.fillna(\"Unknown\", inplace=True)\n",
    "student_jobs.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa289c",
   "metadata": {},
   "source": [
    "## 6. Standardize Column Names\n",
    "\n",
    "Rename columns to follow a consistent naming convention using `.rename()` or by assigning to `.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a096b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert all column names to lowercase and replace spaces with underscores\n",
    "students.columns = [col.lower().replace(\" \", \"_\") for col in students.columns]\n",
    "courses.columns = [col.lower().replace(\" \", \"_\") for col in courses.columns]\n",
    "student_jobs.columns = [col.lower().replace(\" \", \"_\") for col in student_jobs.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89aafbc",
   "metadata": {},
   "source": [
    "## 7. Convert Data Types if Necessary\n",
    "\n",
    "Use `.astype()` to convert columns to appropriate data types (e.g., dates, categories, integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14106348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert 'enrollment_date' in students to datetime\n",
    "if 'enrollment_date' in students.columns:\n",
    "    students['enrollment_date'] = pd.to_datetime(students['enrollment_date'], errors='coerce')\n",
    "\n",
    "# Example: Convert 'course_id' in courses to category\n",
    "if 'course_id' in courses.columns:\n",
    "    courses['course_id'] = courses['course_id'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6028670",
   "metadata": {},
   "source": [
    "## 8. Reshape Data (if needed)\n",
    "\n",
    "Use pandas functions like `.melt()`, `.pivot()`, or `.stack()` to reshape data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ac3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Pivot student_jobs to see job counts per student\n",
    "if 'student_id' in student_jobs.columns and 'job_title' in student_jobs.columns:\n",
    "    job_counts = student_jobs.pivot_table(index='student_id', columns='job_title', aggfunc='size', fill_value=0)\n",
    "    print(job_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb56837",
   "metadata": {},
   "source": [
    "## 9. Merge DataFrames\n",
    "\n",
    "Use `pandas.merge()` to combine DataFrames based on common keys for integrated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89411bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merge students with student_jobs on 'student_id'\n",
    "if 'student_id' in students.columns and 'student_id' in student_jobs.columns:\n",
    "    students_jobs_merged = pd.merge(students, student_jobs, on='student_id', how='left')\n",
    "\n",
    "# Example: Merge with courses if relevant key exists\n",
    "if 'course_id' in students.columns and 'course_id' in courses.columns:\n",
    "    full_data = pd.merge(students_jobs_merged, courses, on='course_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242cec9",
   "metadata": {},
   "source": [
    "## 10. Save Cleaned Data\n",
    "\n",
    "Export the cleaned and tidied DataFrames to CSV or other formats using `.to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ffb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.to_csv(\"cleaned_students.csv\", index=False)\n",
    "courses.to_csv(\"cleaned_courses.csv\", index=False)\n",
    "student_jobs.to_csv(\"cleaned_student_jobs.csv\", index=False)\n",
    "\n",
    "# Save merged DataFrame if created\n",
    "if 'full_data' in locals():\n",
    "    full_data.to_csv(\"cleaned_full_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
