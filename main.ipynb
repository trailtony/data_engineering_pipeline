{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd06d25",
   "metadata": {},
   "source": [
    "# Step by Step: Wrangling and Tidying Data from SQLite Tables\n",
    "\n",
    "This notebook demonstrates a systematic approach to wrangle and tidy data from SQLite tables using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0667a35",
   "metadata": {},
   "source": [
    "## 1. Load Data from SQLite Tables\n",
    "\n",
    "Use `pandas.read_sql_query` to load the tables (`students`, `courses`, `student_jobs`) from the SQLite database into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e75cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "con = sqlite3.connect(\"cademycode.db\")\n",
    "\n",
    "# Load tables into DataFrames\n",
    "students = pd.read_sql_query(\"SELECT * FROM cademycode_students\", con)\n",
    "courses = pd.read_sql_query(\"SELECT * FROM cademycode_courses\", con)\n",
    "student_jobs = pd.read_sql_query(\"SELECT * FROM cademycode_student_jobs\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77aa54",
   "metadata": {},
   "source": [
    "## 2. Inspect DataFrames\n",
    "\n",
    "Use `.head()`, `.info()`, and `.describe()` to get an overview of the data and identify potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb730d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect students DataFrame\n",
    "print(students.head())\n",
    "print(students.info())\n",
    "print(students.describe(include='all'))\n",
    "\n",
    "# Inspect courses DataFrame\n",
    "print(courses.head())\n",
    "print(courses.info())\n",
    "print(courses.describe(include='all'))\n",
    "\n",
    "# Inspect student_jobs DataFrame\n",
    "print(student_jobs.head())\n",
    "print(student_jobs.info())\n",
    "print(student_jobs.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b2d2c",
   "metadata": {},
   "source": [
    "## 3. Check Data Types\n",
    "\n",
    "Use `.dtypes` to review column data types and ensure they match expected formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Students Data Types:\")\n",
    "print(students.dtypes)\n",
    "\n",
    "print(\"\\nCourses Data Types:\")\n",
    "print(courses.dtypes)\n",
    "\n",
    "print(\"\\nStudent Jobs Data Types:\")\n",
    "print(student_jobs.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dda9a",
   "metadata": {},
   "source": [
    "## 4. Remove Duplicate Rows\n",
    "\n",
    "Use `.drop_duplicates(inplace=True)` to remove duplicate entries from each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b791d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.drop_duplicates(inplace=True)\n",
    "courses.drop_duplicates(inplace=True)\n",
    "student_jobs.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cd21c",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values\n",
    "\n",
    "Use `.isna().sum()` to identify missing values and decide on strategies (drop, fill, or impute) for handling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90028f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in students:\")\n",
    "print(students.isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in courses:\")\n",
    "print(courses.isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in student_jobs:\")\n",
    "print(student_jobs.isna().sum())\n",
    "\n",
    "# Example: Drop rows with missing values (customize as needed)\n",
    "students.dropna(inplace=True)\n",
    "courses.fillna(\"Unknown\", inplace=True)\n",
    "student_jobs.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa289c",
   "metadata": {},
   "source": [
    "## 6. Standardize Column Names\n",
    "\n",
    "Rename columns to follow a consistent naming convention using `.rename()` or by assigning to `.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert all column names to lowercase and replace spaces with underscores\n",
    "students.columns = [col.lower().replace(\" \", \"_\") for col in students.columns]\n",
    "courses.columns = [col.lower().replace(\" \", \"_\") for col in courses.columns]\n",
    "student_jobs.columns = [col.lower().replace(\" \", \"_\") for col in student_jobs.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89aafbc",
   "metadata": {},
   "source": [
    "## 7. Convert Data Types if Necessary\n",
    "\n",
    "Use `.astype()` to convert columns to appropriate data types (e.g., dates, categories, integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14106348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert 'enrollment_date' in students to datetime\n",
    "if 'enrollment_date' in students.columns:\n",
    "    students['enrollment_date'] = pd.to_datetime(students['enrollment_date'], errors='coerce')\n",
    "\n",
    "# Example: Convert 'course_id' in courses to category\n",
    "if 'course_id' in courses.columns:\n",
    "    courses['course_id'] = courses['course_id'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6028670",
   "metadata": {},
   "source": [
    "## 8. Reshape Data (if needed)\n",
    "\n",
    "Use pandas functions like `.melt()`, `.pivot()`, or `.stack()` to reshape data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Pivot student_jobs to see job counts per student\n",
    "if 'student_id' in student_jobs.columns and 'job_title' in student_jobs.columns:\n",
    "    job_counts = student_jobs.pivot_table(index='student_id', columns='job_title', aggfunc='size', fill_value=0)\n",
    "    print(job_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb56837",
   "metadata": {},
   "source": [
    "## 9. Merge DataFrames\n",
    "\n",
    "Use `pandas.merge()` to combine DataFrames based on common keys for integrated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89411bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merge students with student_jobs on 'student_id'\n",
    "if 'student_id' in students.columns and 'student_id' in student_jobs.columns:\n",
    "    students_jobs_merged = pd.merge(students, student_jobs, on='student_id', how='left')\n",
    "\n",
    "# Example: Merge with courses if relevant key exists\n",
    "if 'course_id' in students.columns and 'course_id' in courses.columns:\n",
    "    full_data = pd.merge(students_jobs_merged, courses, on='course_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242cec9",
   "metadata": {},
   "source": [
    "## 10. Save Cleaned Data\n",
    "\n",
    "Export the cleaned and tidied DataFrames to CSV or other formats using `.to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.to_csv(\"cleaned_students.csv\", index=False)\n",
    "courses.to_csv(\"cleaned_courses.csv\", index=False)\n",
    "student_jobs.to_csv(\"cleaned_student_jobs.csv\", index=False)\n",
    "\n",
    "# Save merged DataFrame if created\n",
    "if 'full_data' in locals():\n",
    "    full_data.to_csv(\"cleaned_full_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
